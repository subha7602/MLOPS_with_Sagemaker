{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1193ccc2-dce4-4ae6-a814-d29add80c266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def load_dataset(path):\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    files = [ os.path.join(path, file) for file in os.listdir(path) ]\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        raise ValueError(\"Invalid # of files in dir: {}\".format(path))\n",
    "\n",
    "    raw_data = [ pd.read_csv(file, sep=\",\", header=None ) for file in files ]\n",
    "    data = pd.concat(raw_data)\n",
    "\n",
    "    # labels are in the first column\n",
    "    y = data.iloc[:,0]\n",
    "    X = data.iloc[:,1:]\n",
    "    return X,y\n",
    "    \n",
    "def start(args):\n",
    "    print(\"Training mode\")\n",
    "\n",
    "    try:\n",
    "        X_train, y_train = load_dataset(args.train)\n",
    "        X_test, y_test = load_dataset(args.validation)\n",
    "        \n",
    "        hyperparameters = {\n",
    "            \"max_depth\": args.max_depth,\n",
    "            \"verbose\": 1, # show all logs\n",
    "            \"n_jobs\": args.n_jobs,\n",
    "            \"n_estimators\": args.n_estimators\n",
    "        }\n",
    "        print(\"Training the classifier\")\n",
    "        model = RandomForestClassifier()\n",
    "        model.set_params(**hyperparameters)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"Score: {}\".format( model.score(X_test, y_test)) )\n",
    "        joblib.dump(model, open(os.path.join(args.model_dir, \"iris_model.pkl\"), \"wb\"))\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failureReason in the\n",
    "        # DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(args.output_dir, \"failure\"), \"w\") as s:\n",
    "            s.write(\"Exception during training: \" + str(e) + \"\\\\n\" + trc)\n",
    "            \n",
    "        # Printing this causes the exception to be in the training job logs, as well.\n",
    "        print(\"Exception during training: \" + str(e) + \"\\\\n\" + trc, file=sys.stderr)\n",
    "        \n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230e08a4-32ce-472b-9fda-8a2c5e37d472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile handler.py\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from sagemaker_inference.default_inference_handler import DefaultInferenceHandler\n",
    "from sagemaker_inference.default_handler_service import DefaultHandlerService\n",
    "from sagemaker_inference import content_types, errors, transformer, encoder, decoder\n",
    "\n",
    "class HandlerService(DefaultHandlerService, DefaultInferenceHandler):\n",
    "    def __init__(self):\n",
    "        op = transformer.Transformer(default_inference_handler=self)\n",
    "        super(HandlerService, self).__init__(transformer=op)\n",
    "    \n",
    "    ## Loads the model from the disk\n",
    "    def default_model_fn(self, model_dir):\n",
    "        model_filename = os.path.join(model_dir, \"iris_model.pkl\")\n",
    "        return joblib.load(open(model_filename, \"rb\"))\n",
    "    \n",
    "    ## Parse and check the format of the input data\n",
    "    def default_input_fn(self, input_data, content_type):\n",
    "        if content_type != \"text/csv\":\n",
    "            raise Exception(\"Invalid content-type: %s\" % content_type)\n",
    "        return decoder.decode(input_data, content_type).reshape(1,-1)\n",
    "    \n",
    "    ## Run our model and do the prediction\n",
    "    def default_predict_fn(self, payload, model):\n",
    "        return model.predict( payload ).tolist()\n",
    "    \n",
    "    ## Gets the prediction output and format it to be returned to the user\n",
    "    def default_output_fn(self, prediction, accept):\n",
    "        if accept != \"text/csv\":\n",
    "            raise Exception(\"Invalid accept: %s\" % accept)\n",
    "        return encoder.encode(prediction, accept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65ddd51-e708-46ec-b6c5-9fd3d194e9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import train\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "from sagemaker_inference import model_server\n",
    "from sagemaker_training import environment\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2 or ( not sys.argv[1] in [ \"serve\", \"train\" ] ):\n",
    "        raise Exception(\"Invalid argument: you must inform 'train' for training mode or 'serve' predicting mode\") \n",
    "        \n",
    "    if sys.argv[1] == \"train\":\n",
    "        \n",
    "        env = environment.Environment()\n",
    "        \n",
    "        parser = argparse.ArgumentParser()\n",
    "        # https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md\n",
    "        parser.add_argument(\"--max-depth\", type=int, default=10)\n",
    "        parser.add_argument(\"--n-jobs\", type=int, default=env.num_cpus)\n",
    "        parser.add_argument(\"--n-estimators\", type=int, default=120)\n",
    "        \n",
    "        # reads input channels training and testing from the environment variables\n",
    "        parser.add_argument(\"--train\", type=str, default=env.channel_input_dirs[\"train\"])\n",
    "        parser.add_argument(\"--validation\", type=str, default=env.channel_input_dirs[\"validation\"])\n",
    "\n",
    "        parser.add_argument(\"--model-dir\", type=str, default=env.model_dir)\n",
    "        parser.add_argument(\"--output-dir\", type=str, default=env.output_dir)\n",
    "        \n",
    "        args,unknown = parser.parse_known_args()\n",
    "        train.start(args)\n",
    "    else:\n",
    "        model_server.start_model_server(handler_service=\"serving.handler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e83da4f-d4b6-4d24-9dc0-5ca459898823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.7-buster\n",
    "\n",
    "# Set a docker label to advertise multi-model support on the container\n",
    "LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
    "# Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present\n",
    "LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
    "RUN rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
    "RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "COPY main.py /opt/ml/code/main.py\n",
    "COPY train.py /opt/ml/code/train.py\n",
    "COPY handler.py /opt/ml/code/serving/handler.py\n",
    "\n",
    "ENTRYPOINT [\"python\", \"/opt/ml/code/main.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c4c8f3-75d4-4f55-b7a8-41e1b3c01fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing buildspec.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildspec.yml\n",
    "version: 0.2\n",
    "\n",
    "phases:\n",
    "  install:\n",
    "    runtime-versions:\n",
    "      docker: 18\n",
    "\n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo Logging in to Amazon ECR...\n",
    "      - $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
    "  build:\n",
    "    commands:\n",
    "      - echo Build started on `date`\n",
    "      - echo Building the Docker image...\n",
    "      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
    "      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "\n",
    "  post_build:\n",
    "    commands:\n",
    "      - echo Build completed on `date`\n",
    "      - echo Pushing the Docker image...\n",
    "      - echo docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - echo $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG > image.url\n",
    "      - echo Done\n",
    "artifacts:\n",
    "  files:\n",
    "    - image.url\n",
    "  name: image_url\n",
    "  discard-paths: yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8befa43d-8f67-4d44-8816-51d05d3b491d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRECATED: The legacy builder is deprecated and will be removed in a future release.\n",
      "            BuildKit is currently disabled; enable it by removing the DOCKER_BUILDKIT=0\n",
      "            environment-variable.\n",
      "\n",
      "Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n"
     ]
    }
   ],
   "source": [
    "!docker build -f Dockerfile -t iris_model:1.0 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1b0bd2a-e5bd-4610-b411-407bf916d2ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3673499175.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    export DOCKER_BUILDKIT=1\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "export DOCKER_BUILDKIT=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ed7eb0-93ba-4f96-868a-544df3964944",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3275204144.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    aws ecr get-login --region us-east1 --no-include-email\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "aws ecr get-login --region us-east1 --no-include-email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1304f60c-6a10-417d-a28b-7b92f44d3f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\n",
      "To see help text, you can run:\n",
      "\n",
      "  aws help\n",
      "  aws <command> help\n",
      "  aws <command> <subcommand> help\n",
      "\n",
      "aws: error: argument operation: Invalid choice, valid choices are:\n",
      "\n",
      "batch-check-layer-availability           | batch-delete-image                      \n",
      "batch-get-image                          | batch-get-repository-scanning-configuration\n",
      "complete-layer-upload                    | create-pull-through-cache-rule          \n",
      "create-repository                        | create-repository-creation-template     \n",
      "delete-lifecycle-policy                  | delete-pull-through-cache-rule          \n",
      "delete-registry-policy                   | delete-repository                       \n",
      "delete-repository-creation-template      | delete-repository-policy                \n",
      "describe-image-replication-status        | describe-image-scan-findings            \n",
      "describe-images                          | describe-pull-through-cache-rules       \n",
      "describe-registry                        | describe-repositories                   \n",
      "describe-repository-creation-templates   | get-account-setting                     \n",
      "get-authorization-token                  | get-download-url-for-layer              \n",
      "get-lifecycle-policy                     | get-lifecycle-policy-preview            \n",
      "get-registry-policy                      | get-registry-scanning-configuration     \n",
      "get-repository-policy                    | initiate-layer-upload                   \n",
      "list-images                              | list-tags-for-resource                  \n",
      "put-account-setting                      | put-image                               \n",
      "put-image-scanning-configuration         | put-image-tag-mutability                \n",
      "put-lifecycle-policy                     | put-registry-policy                     \n",
      "put-registry-scanning-configuration      | put-replication-configuration           \n",
      "set-repository-policy                    | start-image-scan                        \n",
      "start-lifecycle-policy-preview           | tag-resource                            \n",
      "untag-resource                           | update-pull-through-cache-rule          \n",
      "update-repository-creation-template      | upload-layer-part                       \n",
      "validate-pull-through-cache-rule         | get-login-password                      \n",
      "wait                                     | help                                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login --region us-east-1 --no-include-email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "610e5461-017c-4d25-b931-78a74f7a239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/sagemaker-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credential-stores\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 853973692277.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce695a44-80e1-4483-accd-23d110a6c920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRECATED: The legacy builder is deprecated and will be removed in a future release.\n",
      "            BuildKit is currently disabled; enable it by removing the DOCKER_BUILDKIT=0\n",
      "            environment-variable.\n",
      "\n",
      "Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n"
     ]
    }
   ],
   "source": [
    "!docker build -f Dockerfile -t iris_model:1.0 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ab5e92-b3e9-4b6b-a838-59cf378a9600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sudo: systemctl: command not found\n"
     ]
    }
   ],
   "source": [
    "!sudo systemctl status docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5e666fd-3388-4d05-98d5-6644439fdb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: unrecognized service\n"
     ]
    }
   ],
   "source": [
    "!sudo service docker status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc6bc435-6714-48d1-8afe-30f3046f8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (7.1.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from docker) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.11/site-packages (from docker) (1.26.19)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->docker) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->docker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->docker) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e471dd1-fe73-46f0-a9b4-44f99ae81a62",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3369212131.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    sudo usermod -aG docker $(whoami)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sudo usermod -aG docker $(whoami)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "627673fd-d6a5-4fab-8355-df2354f6ac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usermod: group 'docker' does not exist\n"
     ]
    }
   ],
   "source": [
    "!sudo usermod -aG docker $(whoami)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b670f9dc-37d7-43b7-ad5f-6843333b0ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: unrecognized service\n"
     ]
    }
   ],
   "source": [
    "!sudo service docker status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c2b3351-cbc9-4140-808c-610258ed57f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker version unknown-version, build unknown-commit\n"
     ]
    }
   ],
   "source": [
    "!docker --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46e06093-4e0a-4641-a9c6-e185fd9d1c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRECATED: The legacy builder is deprecated and will be removed in a future release.\n",
      "            BuildKit is currently disabled; enable it by removing the DOCKER_BUILDKIT=0\n",
      "            environment-variable.\n",
      "\n",
      "Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n"
     ]
    }
   ],
   "source": [
    "!docker build -f Dockerfile -t iris_model:1.0 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd38670-ee83-4f0a-8301-711079cae5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf input\n",
    "!mkdir -p input/data/train\n",
    "!mkdir -p input/data/validation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "dataset = np.insert(iris.data, 0, iris.target,axis=1)\n",
    "\n",
    "df = pd.DataFrame(data=dataset, columns=[\"iris_id\"] + iris.feature_names)\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df.insert(0, \"iris_id\", y_train)\n",
    "train_df.to_csv(\"input/data/train/training.csv\", sep=\",\", header=None, index=None)\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df.insert(0, \"iris_id\", y_test)\n",
    "test_df.to_csv(\"input/data/validation/testing.csv\", sep=\",\", header=None, index=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e41054-36e8-4e09-837e-d90ed9583c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
